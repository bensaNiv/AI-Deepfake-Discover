# CLAUDE.md - Project Context for Claude

## Project Overview

Project 9 - AI Video Fraud Detection Agent

This is an experiment-based project that creates a security expert agent specialized in investigating video frauds. The agent analyzes videos (or video frames) and determines whether they were generated by AI or are authentic footage.

## Experiment Description

The experiment flow:
1. Provide a video or image frame to the agent
2. Agent analyzes the content for AI-generation indicators
3. Agent returns a verdict (AI_GENERATED, AUTHENTIC, or UNCERTAIN) with confidence and reasoning

## Quick Start

```bash
# Setup
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
pip install -r requirements.txt
cp .env.example .env

# Analyze a single image
python -m src.main --image path/to/frame.jpg

# Analyze with JSON output
python -m src.main --image path/to/frame.jpg --json

# Run tests
pytest tests/ -v
```

## Project Structure

- `src/` - Source code
  - `agent.py` - Main VideoFraudDetectionAgent class
  - `main.py` - CLI entry point
- `tests/` - Test suite
- `docs/` - Documentation
  - `prompts.md` - Agent prompts and experiment prompts
  - `architecture.md` - System architecture
  - `research.md` - Research methodology
- `data/` - Test videos and images
- `results/` - Experiment outputs
- `notebooks/` - Analysis notebooks

## Key Files

- `src/agent.py` - The VideoFraudDetectionAgent class with detection logic
- `src/main.py` - CLI interface for running analyses
- `docs/prompts.md` - Contains the system prompt and experiment design

## Agent Capabilities

The agent looks for:
- Facial analysis (unnatural movements, lighting, blurring)
- Temporal consistency (flickering, shadows, motion blur)
- Technical artifacts (compression, resolution, color banding)
- Contextual analysis (background, lighting direction, reflections)

## Configuration

Set in `.env`:
- `OLLAMA_HOST` - Ollama server URL (default: http://localhost:11434)
- `LOG_LEVEL` - Logging level

## Development Notes

- Currently supports Ollama with vision models (llava)
- OpenAI and Anthropic providers are stubbed but not implemented
- Video frame extraction requires additional implementation (opencv/ffmpeg)
