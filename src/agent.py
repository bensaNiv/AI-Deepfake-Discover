"""Video Fraud Detection Agent.

A security expert agent specialized in investigating video frauds
and detecting AI-generated video content.
"""

import base64
from pathlib import Path

from .models import AnalysisResult, Verdict
from .parsing import aggregate_results, parse_llm_response
from .providers import query_anthropic, query_ollama, query_openai
from .video_utils import cleanup_temp_files, extract_frames


class VideoFraudDetectionAgent:
    """Security expert agent for detecting AI-generated videos.

    This agent analyzes video content to determine if it was
    generated by AI or is authentic footage.

    Attributes:
        model_provider: The LLM provider ('ollama', 'openai', 'anthropic')
        model_name: The specific model to use
    """

    def __init__(self, model_provider: str = "ollama", model_name: str = "llava"):
        """Initialize the video fraud detection agent.

        Args:
            model_provider: The LLM provider ('ollama', 'openai', 'anthropic')
            model_name: The specific model to use
        """
        self.model_provider = model_provider
        self.model_name = model_name
        self._temp_dir: str | None = None

    def analyze_frame(self, frame_path: str | Path) -> AnalysisResult:
        """Analyze a single video frame for AI generation indicators.

        Args:
            frame_path: Path to the frame image file

        Returns:
            AnalysisResult with verdict and analysis details
        """
        frame_path = Path(frame_path)
        if not frame_path.exists():
            raise FileNotFoundError(f"Frame not found: {frame_path}")

        image_data = self._load_image(frame_path)
        response = self._query_llm(image_data, frame_path.name)
        return parse_llm_response(response)

    def analyze_video(
        self, video_path: str | Path, sample_frames: int = 5
    ) -> AnalysisResult:
        """Analyze a video file for AI generation indicators.

        Extracts frames from the video, analyzes each frame, and returns
        a single aggregated verdict for the entire video.

        Args:
            video_path: Path to the video file
            sample_frames: Number of frames to sample for analysis

        Returns:
            AnalysisResult with aggregated verdict and analysis
        """
        video_path = Path(video_path)
        if not video_path.exists():
            raise FileNotFoundError(f"Video not found: {video_path}")

        try:
            frames, self._temp_dir = extract_frames(video_path, sample_frames)
            frame_results = []
            for idx, frame in enumerate(frames):
                print(f"Analyzing frame {idx + 1}/{len(frames)}...")
                result = self.analyze_frame(frame)
                frame_results.append(result)
            return aggregate_results(frame_results)
        finally:
            cleanup_temp_files(self._temp_dir)
            self._temp_dir = None

    def _load_image(self, image_path: Path) -> str:
        """Load and base64 encode an image."""
        with open(image_path, "rb") as f:
            return base64.b64encode(f.read()).decode("utf-8")

    def _query_llm(self, image_data: str, context: str) -> str:
        """Query the LLM with the image for analysis."""
        if self.model_provider == "ollama":
            return query_ollama(self.model_name, image_data, context)
        elif self.model_provider == "openai":
            return query_openai(self.model_name, image_data, context)
        elif self.model_provider == "anthropic":
            return query_anthropic(self.model_name, image_data, context)
        else:
            raise ValueError(f"Unknown model provider: {self.model_provider}")
