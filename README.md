# Project 9 - AI Video Fraud Detection Agent

An experiment-based project that creates a security expert agent specialized in investigating video frauds. The agent analyzes videos or video frames and determines whether they were generated by AI (deepfakes, synthetic media) or are authentic footage.

## Table of Contents

- [Installation](#installation)
- [Usage](#usage)
- [Configuration](#configuration)
- [How It Works](#how-it-works)
- [Testing](#testing)
- [Project Structure](#project-structure)
- [Results](#results)
- [License](#license)

## Installation

### Prerequisites

- Python 3.10+
- Ollama with a vision model (e.g., llava) for local inference
- OR OpenAI/Anthropic API key for cloud inference

### Setup Steps

```bash
# Clone the repository
git clone <repository-url>
cd project9

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Copy environment configuration
cp .env.example .env
# Edit .env with your values (e.g., OLLAMA_HOST)
```

### Ollama Setup (Recommended)

```bash
# Install Ollama (https://ollama.ai)
# Pull a vision model
ollama pull llava
```

## Usage

### Analyze a Single Image/Frame

```bash
# Basic analysis
python -m src.main --image path/to/frame.jpg

# With JSON output
python -m src.main --image path/to/frame.jpg --json

# Using a specific model
python -m src.main --image path/to/frame.jpg --model llava:13b
```

### Analyze a Video (Coming Soon)

```bash
# Analyze video with 5 sampled frames
python -m src.main --video path/to/video.mp4 --frames 5
```

### Command Line Options

| Option | Description | Default |
|--------|-------------|---------|
| `--image` | Path to image/frame to analyze | - |
| `--video` | Path to video file to analyze | - |
| `--frames` | Number of frames to sample from video | 5 |
| `--provider` | LLM provider (ollama, openai, anthropic) | ollama |
| `--model` | Model name to use | llava |
| `--json` | Output results as JSON | False |

## Configuration

### Environment Variables

Set in `.env`:

```bash
# Ollama configuration
OLLAMA_HOST=http://localhost:11434

# Logging
LOG_LEVEL=INFO
```

## How It Works

The agent acts as a senior security expert in digital forensics. When analyzing content, it examines:

1. **Facial Analysis**: Unnatural movements, lighting inconsistencies, blurring
2. **Temporal Consistency**: Flickering, shadow inconsistencies, motion blur
3. **Technical Artifacts**: Compression anomalies, resolution issues, color banding
4. **Contextual Analysis**: Background consistency, lighting direction, reflections

### Output

The agent returns:
- **Verdict**: `AI_GENERATED`, `AUTHENTIC`, or `UNCERTAIN`
- **Confidence**: 0-100% confidence in the verdict
- **Reasoning**: Detailed explanation of the analysis
- **Indicators**: Specific signs found during analysis
- **Recommendations**: Suggestions for further investigation

## Testing

```bash
# Run all tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=src --cov-report=term-missing
```

## Project Structure

```
project9/
├── README.md                 # This file
├── CLAUDE.md                # Claude context file
├── requirements.txt          # Python dependencies
├── .gitignore               # Git ignore rules
├── .env.example             # Configuration template
├── pyproject.toml           # Package configuration
├── src/                     # Source code
│   ├── __init__.py
│   ├── agent.py             # VideoFraudDetectionAgent
│   └── main.py              # CLI entry point
├── tests/                   # Test suite
│   ├── __init__.py
│   └── conftest.py
├── docs/                    # Documentation
│   ├── prompts.md           # Agent prompts
│   ├── architecture.md      # System architecture
│   └── research.md          # Research methodology
├── data/                    # Test data
│   ├── raw/                 # Original test files
│   └── processed/           # Processed data
├── results/                 # Experiment outputs
│   ├── figures/             # Visualizations
│   └── metrics/             # Analysis metrics
├── notebooks/               # Jupyter notebooks
├── scripts/                 # Utility scripts
└── config/                  # Configuration files
```

## Results

Experiment results will be documented here after running analyses on test datasets.

See `notebooks/` for detailed analysis and `results/` for raw outputs.

## License

MIT License

## Credits

- Ollama for local LLM inference
- LLaVA model for vision capabilities
