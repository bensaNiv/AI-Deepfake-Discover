# Project 9 - AI Video Fraud Detection Agent

An experiment-based project that creates a security expert agent specialized in investigating video frauds. The agent analyzes videos or video frames and determines whether they were generated by AI (deepfakes, synthetic media) or are authentic footage.

## Table of Contents

- [Installation](#installation)
- [Usage](#usage)
- [Configuration](#configuration)
- [How It Works](#how-it-works)
- [Testing](#testing)
- [Project Structure](#project-structure)
- [Results](#results)
- [License](#license)

## Installation

### Prerequisites

- Python 3.10+
- Ollama with a vision model (e.g., llava) for local inference
- OR OpenAI/Anthropic API key for cloud inference

### Setup Steps

```bash
# Clone the repository
git clone <repository-url>
cd project9

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Copy environment configuration
cp .env.example .env
# Edit .env with your values (e.g., OLLAMA_HOST)
```

### Ollama Setup (Recommended)

```bash
# Install Ollama (https://ollama.ai)
# Pull a vision model
ollama pull llava
```

## Usage

### Analyze a Single Image/Frame

```bash
# Basic analysis
python -m src.main --image path/to/frame.jpg

# With JSON output
python -m src.main --image path/to/frame.jpg --json

# Using a specific model
python -m src.main --image path/to/frame.jpg --model llava:13b
```

### Analyze a Video (Coming Soon)

```bash
# Analyze video with 5 sampled frames
python -m src.main --video path/to/video.mp4 --frames 5
```

### Command Line Options

| Option | Description | Default |
|--------|-------------|---------|
| `--image` | Path to image/frame to analyze | - |
| `--video` | Path to video file to analyze | - |
| `--frames` | Number of frames to sample from video | 5 |
| `--provider` | LLM provider (ollama, openai, anthropic) | ollama |
| `--model` | Model name to use | llava |
| `--json` | Output results as JSON | False |

## Configuration

### Environment Variables

Set in `.env`:

```bash
# Ollama configuration
OLLAMA_HOST=http://localhost:11434

# Logging
LOG_LEVEL=INFO
```

## How It Works

The agent acts as a senior security expert in digital forensics. When analyzing content, it examines:

1. **Facial Analysis**: Unnatural movements, lighting inconsistencies, blurring
2. **Temporal Consistency**: Flickering, shadow inconsistencies, motion blur
3. **Technical Artifacts**: Compression anomalies, resolution issues, color banding
4. **Contextual Analysis**: Background consistency, lighting direction, reflections

### Output

The agent returns:
- **Verdict**: `AI_GENERATED`, `AUTHENTIC`, or `UNCERTAIN`
- **Confidence**: 0-100% confidence in the verdict
- **Reasoning**: Detailed explanation of the analysis
- **Indicators**: Specific signs found during analysis
- **Recommendations**: Suggestions for further investigation

## Testing

```bash
# Run all tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=src --cov-report=term-missing
```

## Project Structure

```
project9/
├── README.md                    # This file
├── CLAUDE.md                    # Claude context file
├── requirements.txt             # Python dependencies
├── pyproject.toml               # Package configuration
├── .gitignore                   # Git ignore rules
├── .env.example                 # Configuration template
│
├── src/                         # Source code
│   ├── __init__.py
│   ├── agent.py                 # VideoFraudDetectionAgent
│   └── main.py                  # CLI entry point
│
├── docs/                        # Documentation
│   ├── prompts.md               # Agent prompts documentation
│   ├── llm-video-analysis-prompt.md  # External LLM prompt
│   ├── architecture.md          # System architecture
│   └── research.md              # Research methodology
│
├── videos/                      # Test videos
│   ├── vidoe_1.mp4              # AI-generated
│   ├── video_2.mp4              # AI-generated
│   ├── video_3.mp4              # AI-generated
│   ├── video_4.mp4              # Authentic
│   └── video_5.mp4              # Authentic
│
├── results/                     # Experiment outputs
│   ├── experiment_results.md    # Full analysis report
│   ├── figures/                 # Visualizations
│   │   ├── confidence_by_video.png
│   │   ├── confusion_matrix.png
│   │   └── performance_metrics.png
│   └── metrics/
│       └── experiment_metrics.json
│
├── scripts/                     # Utility scripts
│   └── generate_visualizations.py
│
├── tests/                       # Test suite
│   ├── __init__.py
│   └── conftest.py
│
└── config/                      # Configuration files
```

## Experiment Results

### Overview

We tested the agent on a dataset of 5 videos:
- **3 AI-generated videos** (Videos 1-3)
- **2 authentic videos** (Videos 4-5)

### Performance Summary

| Metric | Value |
|--------|-------|
| **Accuracy** | 80% (4/5) |
| **Precision** | 75% |
| **Recall** | 100% |
| **F1 Score** | 0.857 |

### Model Confidence by Video

![Confidence by Video](results/figures/confidence_by_video.png)

The chart shows model confidence for each video. Green bars indicate correct predictions, red indicates incorrect. The model achieved high confidence (95-98%) across all predictions, but notably the one error (Video 4) also had 98% confidence - indicating a calibration issue.

### Confusion Matrix

![Confusion Matrix](results/figures/confusion_matrix.png)

The model correctly identified all AI-generated videos (100% recall) but produced one false positive - classifying an authentic video as AI-generated.

### Key Findings

1. **High Recall**: The model detected all 3 AI-generated videos correctly
2. **False Positive Risk**: Complex motion in authentic videos can trigger false AI detection
3. **Confidence Calibration**: High confidence doesn't always correlate with correctness
4. **Common AI Indicators**: Morphing artifacts, anatomical inconsistencies, and temporal flickering were the most frequently detected signs

### Detailed Results

See [`results/experiment_results.md`](results/experiment_results.md) for full analysis including per-video breakdowns.

## License

MIT License

## Credits

- Ollama for local LLM inference
- LLaVA model for vision capabilities
